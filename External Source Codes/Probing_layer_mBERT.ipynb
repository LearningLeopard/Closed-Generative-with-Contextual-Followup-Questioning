{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, ClassLabel, DatasetDict\n",
    "from transformers import AutoModel, AutoTokenizer, DataCollatorForTokenClassification, AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import evaluate\n",
    "from transformers import get_scheduler\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPERTY = 'Gender'\n",
    "LAYER_NUMBER = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['words', 'lid', 'Number'],\n",
       "        num_rows: 27893\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['words', 'lid', 'Number'],\n",
       "        num_rows: 4298\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['words', 'lid', 'Number'],\n",
       "        num_rows: 10720\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lince_feature_dataset = load_from_disk(\n",
    "    '../Datasets/Lince_' + \"Number\" + \"_spaeng\")\n",
    "\n",
    "Lince_feature_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = set()\n",
    "\n",
    "for split in Lince_feature_dataset:\n",
    "    dataset = Lince_feature_dataset[split]\n",
    "    for datapoint in dataset:\n",
    "        labels_list.update(datapoint['Gender'])\n",
    "\n",
    "labels_list = list(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['masc', '_', 'fem']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'bert-base-multilingual-uncased', return_tensors='pt')\n",
    "label_all_tokens = True\n",
    "labels_encoder = ClassLabel(names=labels_list)\n",
    "\n",
    "# Tokenizing and aligning the tags\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"words\"], truncation=True, is_split_into_words=True)\n",
    "    examples[\"Gender\"] = [labels_encoder.str2int(\n",
    "        tag) for tag in examples[\"Gender\"]]\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"Gender\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_encoder.str2int('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/chaitanya/Acads/Thesis_Work/Experiments/Code-Switching/Datasets/Lince_Gender_spaeng/train/cache-58d1c04b515ee7ee.arrow\n",
      "Loading cached processed dataset at /home/chaitanya/Acads/Thesis_Work/Experiments/Code-Switching/Datasets/Lince_Gender_spaeng/validation/cache-f84ed1e995aa71e1.arrow\n",
      "Loading cached processed dataset at /home/chaitanya/Acads/Thesis_Work/Experiments/Code-Switching/Datasets/Lince_Gender_spaeng/test/cache-7f94ee2876a5a2c9.arrow\n"
     ]
    }
   ],
   "source": [
    "preprocessed_dataset = Lince_feature_dataset.map(\n",
    "    tokenize_and_align_labels, batched=True)\n",
    "preprocessed_dataset.set_format(\n",
    "    type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mBERTLayerModel(nn.Module):\n",
    "    def __init__(self, checkpoint, num_labels, layer_number):\n",
    "        super(mBERTLayerModel, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.layer_number = layer_number\n",
    "        self.model = AutoModel.from_pretrained(checkpoint, config=AutoConfig.from_pretrained(checkpoint,\n",
    "                                                                                             output_attention=True,\n",
    "                                                                                             output_hidden_states=True))\n",
    "        # self.dropout = nn.Dropout(0.1)\n",
    "#        self.classifier = nn.LSTM(input_size=768, hidden_size=self.num_labels, num_layers=1, batch_first=True)\n",
    "        self.classifier = nn.Linear(\n",
    "            in_features=768, out_features=num_labels, bias=True)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.model(input_ids=input_ids,\n",
    "                             attention_mask=attention_mask)\n",
    "\n",
    "        # last_hidden_state = outputs[0]\n",
    "\n",
    "        bert_embeddings = outputs.hidden_states[self.layer_number]\n",
    "        # print(bert_embeddings.shape)\n",
    "        # sequence_outputs = self.dropout(bert_embeddings)\n",
    "        # print(\"dropout layer output: \", sequence_outputs.shape)\n",
    "        logits = self.classifier(bert_embeddings)\n",
    "        loss = None\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_func = nn.CrossEntropyLoss()\n",
    "            # print(\"Classifier output sent as is shape: \", logits[0].shape)\n",
    "            loss = loss_func(torch.reshape(\n",
    "                logits, (-1, self.num_labels)), labels.view(-1))\n",
    "            # exit()\n",
    "            return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states[self.layer_number], attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "POS_tagger = mBERTLayerModel(checkpoint='bert-base-multilingual-uncased',\n",
    "                             num_labels=len(labels_list), layer_number=LAYER_NUMBER)\n",
    "# POS_tagger.model.requires_grad(False) # Freezing a layer\n",
    "# OR\n",
    "\n",
    "for param in POS_tagger.model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    preprocessed_dataset[\"train\"].select(range(6)), shuffle=True, batch_size=3, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    preprocessed_dataset[\"validation\"].select(range(6)), batch_size=3, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6833df358a2547bc8046d8b613495e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5437eafd2ec040e0a6f7601edf424ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Epoch:  0  =====================\n",
      "{'_': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1}, 'asc': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1}, 'em': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0}, 'overall_precision': 0.0, 'overall_recall': 0.0, 'overall_f1': 0.0, 'overall_accuracy': 0.631578947368421}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaitanya/Acads/Thesis_Work/Experiments/Code-Switching/CSProject/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: _ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/chaitanya/Acads/Thesis_Work/Experiments/Code-Switching/CSProject/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: masc seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/chaitanya/Acads/Thesis_Work/Experiments/Code-Switching/CSProject/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: fem seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/chaitanya/Acads/Thesis_Work/Experiments/Code-Switching/CSProject/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(POS_tagger.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 1\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epochs * len(eval_dataloader)))\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    POS_tagger.train()\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v for k, v in batch.items()}\n",
    "        outputs = POS_tagger(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "    POS_tagger.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = POS_tagger(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        # print(predictions.shape, \"batch:\", batch['labels'].shape)\n",
    "        labels = batch['labels']\n",
    "        true_predictions = [\n",
    "            [labels_encoder.int2str(p.item()) for (\n",
    "                p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [labels_encoder.int2str(l.item()) for (\n",
    "                p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        # for sentence_true_labels, sentence_true_predictions in zip(true_labels, true_predictions):\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "        progress_bar_eval.update(1)\n",
    "    print(\"===================== Epoch: \", epoch, \" =====================\")\n",
    "    print(metric.compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
